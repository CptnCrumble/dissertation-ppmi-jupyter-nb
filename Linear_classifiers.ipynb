{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "1c849a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "updrs_sigfall = pd.read_csv('./working_data/normalised_updrs_sigfall.csv')\n",
    "updrs_sigfall_raw = pd.read_csv('./working_data/normalised_updrs_sigfall_raw.csv')\n",
    "updrs_future_sigfall = pd.read_csv('./working_data/normalised_updrs_future_sigfall.csv')\n",
    "updrs_future_sigfall_raw = pd.read_csv('./working_data/normalised_updrs_future_sigfall_raw.csv')\n",
    "inc_updrs_sigfall = pd.read_csv('./working_data/normalised_increase_updrs_sigfall.csv')\n",
    "inc_updrs_sigfall_raw = pd.read_csv('./working_data/normalised_increase_updrs_sigfall_raw.csv')\n",
    "delta_updrs_sigfall = pd.read_csv('./working_data/normalised_delta_updrs_sigfall.csv')\n",
    "delta_updrs_sigfall_raw = pd.read_csv('./working_data/normalised_delta_updrs_sigfall_raw.csv')\n",
    "\n",
    "data_sources = {'updrs_sigfall': updrs_sigfall,\n",
    "                'updrs_future_sigfall': updrs_future_sigfall,\n",
    "                'inc_updrs_sigfall': inc_updrs_sigfall,\n",
    "                'delta_updrs_sigfall': delta_updrs_sigfall}\n",
    "\n",
    "raw_data_sources = {'updrs_sigfall_raw': updrs_sigfall_raw,\n",
    "                    'updrs_future_sigfall_raw': updrs_future_sigfall_raw,\n",
    "                    'inc_updrs_sigfall_raw': inc_updrs_sigfall_raw,\n",
    "                    'delta_updrs_sigfall_raw': delta_updrs_sigfall_raw }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc3b2e4",
   "metadata": {},
   "source": [
    "## Straight models\n",
    "Running the working data directly through Linear Discriminant Analysis models\n",
    "Each dataset is Cross-fold validated where k=10\n",
    "Results analyzed for like for like comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "5fdff779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_model_score(dataset):\n",
    "    try:\n",
    "        X = dataset.drop(columns=['SIGFALL'])\n",
    "    except:\n",
    "        X = dataset.drop(columns=['SIGFALL_NEXT'])\n",
    "        \n",
    "    try:    \n",
    "        y = dataset['SIGFALL']\n",
    "    except:\n",
    "        y = dataset['SIGFALL_NEXT']\n",
    "\n",
    "    model = LinearDiscriminantAnalysis()\n",
    "    scores = cross_val_score(model, X, y, cv=10)\n",
    "    return scores.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "c3fa03e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updrs_sigfall score of 0.9022084195997238\n",
      "updrs_future_sigfall score of 0.8999999999999998\n",
      "inc_updrs_sigfall score of 0.9101908657123381\n",
      "delta_updrs_sigfall score of 0.9118516769012753\n"
     ]
    }
   ],
   "source": [
    "for k,v in data_sources.items():    \n",
    "    s = lda_model_score(v)\n",
    "    print(f'{k} score of {s}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "c5d6eab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updrs_sigfall_raw score of 0.9022084195997238\n",
      "updrs_future_sigfall_raw score of 0.8999999999999998\n",
      "inc_updrs_sigfall_raw score of 0.9120275694917821\n",
      "delta_updrs_sigfall_raw score of 0.9118516769012753\n"
     ]
    }
   ],
   "source": [
    "for k,v in raw_data_sources.items():    \n",
    "    s = lda_model_score(v)\n",
    "    print(f'{k} score of {s}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce074ce1",
   "metadata": {},
   "source": [
    "## Using confusion matricies to understand errors\n",
    "Inbalances in data lead to bias in model\n",
    "eg if in doubt call it 0\n",
    "\n",
    "investigate the models again, this time analyzing for ????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "a7adb01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_confusion_matrix(dataset):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(dataset.iloc[:, :-1], dataset.iloc[:, -1], test_size=0.1)\n",
    "        lda_model = LinearDiscriminantAnalysis()\n",
    "        predictions = lda_model.fit(X_train, y_train).predict(X_test)\n",
    "        tn, fp, fn, tp = confusion_matrix(predictions, y_test.values).ravel()\n",
    "        return (tn,fp,fn,tp)\n",
    "\n",
    "\n",
    "def analyse_confusion_matrix(cm):\n",
    "    tn, fp, fn, tp = cm\n",
    "    total = (tn + tp)/(fp + fn + tn + tp)\n",
    "    no_fall_accuracy = tn / (tn + fn)\n",
    "    fall_accuracy = tp / (tp + fp)\n",
    "    return (total,no_fall_accuracy,fall_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "20de98b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- updrs_sigfall ---\n",
      "Total 0.9055555555555556\n",
      "No fall 0.9758206399176519\n",
      "Falls 0.1438936063936064\n",
      "\n",
      "--- updrs_future_sigfall ---\n",
      "Total 0.908904109589041\n",
      "No fall 0.9902316458809814\n",
      "Falls 0.0644083694083694\n",
      "\n",
      "--- inc_updrs_sigfall ---\n",
      "Total 0.9098159509202454\n",
      "No fall 0.9793244806764472\n",
      "Falls 0.1136620324120324\n",
      "\n",
      "--- delta_updrs_sigfall ---\n",
      "Total 0.9178082191780822\n",
      "No fall 0.9948026186739878\n",
      "Falls 0.038553113553113555\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For each dataset create 10 models (random test/train splits) and record accuracy\n",
    "\n",
    "for k,v in data_sources.items():\n",
    "    print(f'--- {k} ---')\n",
    "    totals = []\n",
    "    nfs = []\n",
    "    falls = []\n",
    "    for n in range(10):\n",
    "        m = lda_confusion_matrix(v)\n",
    "        t, nf, f = analyse_confusion_matrix(m)\n",
    "        totals.append(t)\n",
    "        nfs.append(nf)\n",
    "        falls.append(f)\n",
    "    avg_total = np.array(totals).mean()\n",
    "    avg_nfs = np.array(nfs).mean()\n",
    "    avg_falls = np.array(falls).mean()\n",
    "    print(f'Total {avg_total}\\nNo fall {avg_nfs}\\nFalls {avg_falls}\\n')\n",
    "    \n",
    "# to do - stick this in a df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "a8641815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- updrs_sigfall_raw ---\n",
      "Total 0.912962962962963\n",
      "No fall 0.9813078782642564\n",
      "Falls 0.1104227145403616\n",
      "\n",
      "--- updrs_future_sigfall_raw ---\n",
      "Total 0.9006849315068493\n",
      "No fall 0.9812166162556639\n",
      "Falls 0.09642680848563201\n",
      "\n",
      "--- inc_updrs_sigfall_raw ---\n",
      "Total 0.9116564417177914\n",
      "No fall 0.980012537204393\n",
      "Falls 0.14357270180799592\n",
      "\n",
      "--- delta_updrs_sigfall_raw ---\n",
      "Total 0.9157534246575342\n",
      "No fall 0.9969810040705562\n",
      "Falls 0.03864468864468864\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k,v in raw_data_sources.items():\n",
    "    print(f'--- {k} ---')\n",
    "    totals = []\n",
    "    nfs = []\n",
    "    falls = []\n",
    "    for n in range(10):\n",
    "        m = lda_confusion_matrix(v)\n",
    "        t, nf, f = analyse_confusion_matrix(m)\n",
    "        totals.append(t)\n",
    "        nfs.append(nf)\n",
    "        falls.append(f)\n",
    "    avg_total = np.array(totals).mean()\n",
    "    avg_nfs = np.array(nfs).mean()\n",
    "    avg_falls = np.array(falls).mean()\n",
    "    print(f'Total {avg_total}\\nNo fall {avg_nfs}\\nFalls {avg_falls}\\n')\n",
    "    \n",
    "# to do - stick this in a df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "95854640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do some Confusion Matrix analysis on loop to allow for analysis\n",
    "# k-fold instead of train test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60889894",
   "metadata": {},
   "source": [
    "## Balanced data set approach\n",
    "What happens if we balance out the sigfall ratios and recreate our models?\n",
    "Can we beat random ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "8a5efb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1096, 270, 577, 212, 754, 759, 222, 506, 16, 1034, 1191, 1060, 1045, 1164, 906, 588, 1415, 26, 497, 211, 1082, 1248, 1118, 1261, 1277, 1410, 648, 843, 452, 512, 1607, 874, 1147, 1014, 548, 328, 168, 1154, 1080, 2, 985, 480, 1124, 969, 1203, 775, 1027, 1507, 1334, 1108, 745, 1579, 665, 639, 1376, 96, 1081, 122, 1391, 1533, 909, 899, 1271, 279, 1115, 1339, 1033, 1606, 1061, 1288, 1498, 479, 272, 456, 370, 1282, 1448, 520, 664, 721, 10, 1443, 981, 378, 108, 289, 1411, 133, 769, 626, 1526, 1035, 742, 1032, 1316, 508, 907, 644, 751, 1497, 1476, 57, 824, 837, 758, 362, 1169, 187, 982, 1610, 393, 1510, 900, 517, 1229, 1471, 1123, 1070, 542, 27, 183, 4, 1015, 1502, 1289, 359, 794, 1137, 1414, 1025, 854, 566, 82, 462, 79, 390, 1311, 368, 1530, 842, 376, 256, 1117, 1011, 955, 214, 166, 764, 531, 311, 165, 195, 1456, 1583, 1421, 1374, 1090, 523, 1303, 1103, 1325, 167, 1262, 307, 1010, 1438, 159, 1494, 537, 1254, 199, 1508, 45, 992, 403, 560, 1230, 849, 1023, 1249, 322, 424, 510, 1275, 1540, 92, 494, 317, 415, 1353, 1461, 1430, 405, 181, 996, 300, 611, 1196, 218, 1156, 1345, 1268, 579, 13, 1383, 244, 1009, 450, 239, 331, 89, 1413, 638, 597, 1563, 39, 1092, 1304, 1170, 1159, 1093, 1371, 299, 922, 464, 831, 1241, 1488, 471, 1238, 727, 1541, 1232, 1246, 129, 1267, 833, 223, 1612, 1309, 338, 1330, 361, 1381, 1512, 990, 1511, 683, 1278, 1037, 1338, 810, 1121, 1059, 1299, 812, 1333, 1136, 1085, 524, 418, 324, 518, 903, 273, 1382, 1091, 581, 697, 993, 1416, 1584, 31, 977, 496, 731, 1146, 65, 157, 249, 287, 283, 1459, 491, 602, 1326, 305, 112, 1177, 1385, 564, 141, 975, 934, 864, 83, 1181, 987, 756, 198, 1160, 1231, 550, 720, 708, 1370, 163, 161, 123, 262, 1405, 1285, 959, 1292, 557, 381, 1216, 912, 345, 348, 1425, 1163, 106, 1483, 1105, 654, 321, 326, 968, 1053, 59, 25, 1537, 528, 90, 43, 1240, 319, 374, 429, 1135, 1574, 877, 1298, 914, 1315, 819, 1046, 392, 404, 522, 544, 747, 1564, 475, 669, 926, 113, 718, 580, 1174, 254, 253, 42, 5, 957, 778, 1263, 1436, 1523, 1504, 1125, 685, 247, 1013, 490, 573, 469, 97, 1478, 807, 852, 1281, 56, 1402, 1134, 410, 1417, 1122, 350, 571, 924, 1572, 236, 1302, 1555, 1429, 1451, 631, 1608, 939, 501, 1051, 1601, 1202, 956, 1423, 1199, 128, 862, 787, 1221, 1505, 838, 1464, 507, 482, 443, 1109, 777, 1377, 988, 1073, 1026, 743, 308, 637, 832, 478, 1406, 1223, 780, 78, 1006, 565, 489, 943, 1556, 465, 948, 188, 570, 313, 1565, 334, 1259, 1379, 474, 472, 1434, 1233, 1140, 6, 145, 1424, 1255, 1366, 1514, 805, 176, 158, 532, 302, 1400, 875, 680, 944, 888, 1226, 1489, 461, 417, 360, 1149, 1193, 984, 879, 1074, 784, 449, 1101, 660, 1470, 109, 1066, 991, 1458, 1129, 553, 1291, 601, 681, 1251, 938, 175, 635, 280, 1509, 947, 1335, 684, 606, 225, 859, 1611, 46, 160, 1178, 749, 428, 1435, 853, 1237, 1460, 666, 330, 533, 85, 828, 908, 433, 701, 316, 741, 118, 1518, 1044, 315, 811, 1161, 772, 377, 1008, 426, 99, 1360, 136, 972, 662, 1197, 1021, 986, 596, 1552, 1057, 192, 48, 902, 285, 559, 1296, 869, 435, 1467, 591, 1319, 363, 1466, 989, 265, 445, 1040, 825, 1144, 1452, 723, 388, 578, 736, 264, 576, 36, 1106, 1534, 1389, 1546, 1527, 1490, 395, 76, 372, 717, 248, 1166, 451, 1256, 229, 719, 1384, 147, 1175, 1348, 352, 436, 438, 1252, 1524, 1539, 34, 936, 529, 891, 197, 627, 1, 1388, 1328, 689, 1336, 1185, 513, 1095, 295, 575, 572, 634, 767, 485, 951, 1128, 1499, 661, 757, 463, 500, 1599, 514, 1528, 54, 318, 486, 656, 200, 120, 554, 802, 1120, 255, 1084, 444, 100, 357, 841, 314, 781, 1558, 860, 670, 349, 41, 425, 20, 861, 202, 590, 1279, 1047, 1030, 551, 98, 224, 1454, 1522, 1179, 603, 729, 310, 965, 1368, 190, 917, 401, 707, 1513, 1468, 511, 14, 1228, 15, 1028, 752, 162, 674, 599, 933, 901, 306, 569, 47, 935, 1094, 998, 730, 1361, 50, 1359, 632, 268, 1587, 1535, 476, 617, 205, 1515, 1297, 1343, 562, 220, 246, 1130, 24, 237, 180, 1187, 801, 1257, 1069, 600, 895, 1098, 840, 354, 1484, 206, 1131, 1186, 1380, 692, 358, 1475, 288, 999, 748, 1153, 149, 653, 655, 1200, 1104, 292, 1431, 1590, 402, 1495, 589, 1582, 785, 803, 105, 822, 1173, 774, 636, 971, 1358, 1301, 201, 1561, 1332, 1532, 127, 446, 584, 179, 1568, 716, 132, 439, 850, 690, 709, 1613, 406, 473, 994, 1477, 765, 1062, 941, 563, 953, 1542, 679, 55, 1506, 1553, 1293, 614, 1463, 574, 171, 873, 70, 124, 1387, 1294, 355, 278, 1453, 1058, 208, 724, 1142, 1349, 117, 1439, 1211, 217, 739, 595, 1183, 1586, 1019, 1276, 431, 483, 855, 325, 1264, 86, 303, 1570, 1571, 263, 997, 1521, 11, 134, 1020, 1474, 1538, 186, 792, 835, 62, 826, 814, 138, 798, 744, 545, 616, 177, 343, 698, 178, 1354, 876, 126, 682, 1065, 119, 1503, 1592, 586, 1363, 87, 905, 839, 1312, 1554, 1594, 541, 414, 364, 484, 1492, 647, 103, 1329, 29, 966, 261, 399, 467, 1321, 695, 1004, 1214, 1107, 75, 1067, 1496, 1273, 1520, 872, 1369, 1399, 421, 870, 1501, 383, 737, 940, 561, 1603, 808, 194, 341, 1408, 69, 582, 1393, 1614, 74, 913, 534, 1566, 630, 209, 131, 389, 38, 329, 1397, 642, 416, 594, 61, 668, 1549, 110, 918, 621, 88, 556, 676, 1258, 260, 216, 1056, 954, 409, 856, 651, 1176, 164, 67, 1024, 788, 846, 1576, 858, 628, 172, 1063, 952, 235, 633, 1449, 1016, 1469, 710, 789, 593, 1318, 740, 257, 1516, 1210, 1089, 796, 539, 1455, 1155, 608, 865, 898, 391, 207, 1344, 882, 1219, 63, 323, 1222, 1589, 1609, 844, 1132, 210, 1392, 297, 536, 1213, 1192, 1409, 658, 1139, 1347, 659, 1225, 7, 1110, 1593, 1012, 1395, 371, 95, 1367, 1580, 663, 1209, 783, 791, 219, 688, 889, 1287, 1375, 552, 1422, 890, 1331, 945, 1308, 1243, 44, 1116, 1597, 1525, 1239, 923, 687, 693, 1445, 459, 995, 1097, 691, 250, 73, 301, 1007, 770, 509, 980, 346, 1493, 1327, 240, 335, 252, 1077, 1531, 154, 505, 1260, 1536, 353, 1189, 827, 1604, 101, 726, 1472, 1269, 609, 351, 488, 365, 949, 447, 881, 28, 1577, 1605, 420, 394, 1491, 1224, 1481, 174, 411, 1042, 1401, 189, 379, 385, 543, 115, 1557, 193, 144, 1403, 1314, 1152, 1602, 1295, 432, 340, 753, 504, 33, 477, 32, 111, 1562, 457, 612, 919, 694, 894, 1002, 863, 646, 650, 230, 1324, 80, 604, 1151, 1102, 68, 641, 1114, 1078, 1500, 396, 116, 440, 773, 815, 58, 1086, 23, 274, 629, 1394, 298, 1075, 114, 71, 1487, 9, 1426, 1559, 259, 649, 94, 1266, 1588, 152, 613, 567, 521, 804, 66, 1195, 1307, 271, 1076, 266, 857, 1543, 1378, 8, 1198, 930, 234, 1286, 1234, 1148, 795, 30, 1141, 1420, 974, 920, 516, 546, 1362, 1519, 1182, 967, 1274, 979, 1300, 1280, 1052, 549, 53, 296, 498, 332, 369, 735, 238, 640, 339, 130, 530, 258, 836, 1071, 1581, 487, 728, 398, 976, 761, 799, 1442, 845, 1486, 269, 535, 21, 715, 916, 1270, 1029, 813, 848, 140, 1253, 1569, 1390, 878, 430, 946, 983, 911, 1184, 1465, 615, 373, 1083, 526, 1355, 587, 1265, 1220, 1157, 102, 738, 1000, 978, 146, 1055, 722, 277, 1373, 12, 251, 453, 242, 1337, 1479, 1317, 1127, 1305, 400, 555, 408, 1398, 1054, 816, 897, 620, 336, 657, 585, 1138, 1113, 1119, 1544, 1585, 671, 1205, 610, 468, 182, 1218, 1038, 1072, 1446, 148, 221, 1310, 1447, 1143, 419, 91, 1201, 241, 1444, 1235, 84, 384, 618, 1208, 925, 81, 1372, 762, 1320, 931, 333, 93, 1396, 1180, 1578, 885, 407, 786, 1242, 515, 592, 643, 1100, 470, 820, 896, 1433, 704, 1165, 725, 790, 35, 121, 1551, 422, 830, 937, 821, 1049, 625, 851, 779, 455, 367, 347, 342, 423, 454, 60, 413, 519, 281, 1079, 215, 493, 942, 1412, 1567, 771, 1112, 904, 706, 1407, 1596, 1018, 1462, 678]\n"
     ]
    }
   ],
   "source": [
    "# Get \n",
    "sigfall_indexes = updrs_sigfall.index[updrs_sigfall['SIGFALL'] == 0].to_list()\n",
    "n_falls = len(updrs_sigfall) - len(sigfall_indexes)\n",
    "drop = len(sigfall_indexes) - n_falls\n",
    "random.shuffle(sigfall_indexes)\n",
    "\n",
    "print(sigfall_indexes[0:drop])\n",
    "\n",
    "# now drop those indexes to create a balanced data set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
