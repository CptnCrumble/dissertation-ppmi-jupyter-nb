{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "749b57ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "\n",
    "def build_confusion_matrix(dataset, model):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(dataset.iloc[:, :-1], dataset.iloc[:, -1], test_size=0.25)\n",
    "        predictions = model.fit(X_train, y_train).predict(X_test)\n",
    "        tn, fn, fp, tp = confusion_matrix(predictions, y_test.values).ravel()\n",
    "        return {'true_negative': tn, 'false_negative': fn, 'false_positive': fp, 'true_positive': tp}\n",
    "\n",
    "def sensitivity(cm):\n",
    "    return cm['true_positive'] / (cm['true_positive'] + cm['false_negative'])\n",
    "\n",
    "def specificity(cm):\n",
    "    return cm['true_negative'] / ( cm['true_negative'] + cm['false_positive'] )\n",
    "\n",
    "def false_positive_rate(cm):\n",
    "    return (1.0 - (specificity(cm)) )\n",
    "\n",
    "def generate_scores(dataset, model):\n",
    "    specificity_scores = []\n",
    "    sensitivity_scores = []\n",
    "\n",
    "    for n in range(1000):\n",
    "        cm = build_confusion_matrix(dataset, model)\n",
    "        specificity_scores.append(specificity(cm))\n",
    "        sensitivity_scores.append(sensitivity(cm))\n",
    "    \n",
    "    spec_avg = pd.Series(specificity_scores).mean()\n",
    "    sens_avg = pd.Series(sensitivity_scores).mean()\n",
    "    \n",
    "    return {'specificity': spec_avg, 'sensitivity': sens_avg }\n",
    "\n",
    "def summarise_test(test):\n",
    "    x ='For {}, in model {}\\nAverage NO SIGFALL accuracy is {}\\nAverage SIGFALL accuracy is {}\\n---\\n'\n",
    "    print(x.format(test['data_name'],test['model'],test['specificity'],test['sensitivity']))\n",
    "\n",
    "def balance_data_set(dataset, classifier):\n",
    "    sigfall_indexes = dataset.index[dataset[classifier] == 0].to_list()\n",
    "    n_falls = len(dataset) - len(sigfall_indexes)\n",
    "    drop = len(sigfall_indexes) - n_falls\n",
    "    random.shuffle(sigfall_indexes)\n",
    "    drop_indexes = sigfall_indexes[0:drop]\n",
    "    return dataset.drop(drop_indexes)\n",
    "\n",
    "# Balance_data_generate_scores() is a seperate function to invoke a new randomly balanced dataset in each iteration.\n",
    "# If a dataset was pre-balanced then run through generate_scores() it would overfit to that specific dataset \n",
    "\n",
    "def balance_data_generate_scores(dataset, classifier, model):\n",
    "    specificity_scores = []\n",
    "    sensitivity_scores = []\n",
    "\n",
    "    for n in range(1000):\n",
    "        b_dataset = balance_data_set(dataset, classifier)\n",
    "        cm = build_confusion_matrix(b_dataset, model)\n",
    "        specificity_scores.append(specificity(cm))\n",
    "        sensitivity_scores.append(sensitivity(cm))\n",
    "    \n",
    "    spec_avg = pd.Series(specificity_scores).mean()\n",
    "    sens_avg = pd.Series(sensitivity_scores).mean()\n",
    "    \n",
    "    return {'specificity': spec_avg, 'sensitivity': sens_avg }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "596aba1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data sets\n",
    "inc_updrs_sigfall = pd.read_csv('./working_data/normalised_increase_updrs_sigfall.csv')\n",
    "inc_updrs_sigfall_raw = pd.read_csv('./working_data/increase_updrs_sigfall_raw.csv')\n",
    "delta_updrs_sigfall = pd.read_csv('./working_data/normalised_delta_updrs_sigfall.csv')\n",
    "delta_updrs_sigfall_raw = pd.read_csv('./working_data/delta_updrs_sigfall_raw.csv')\n",
    "updrs_future_sigfall = pd.read_csv('./working_data/normalised_updrs_future_sigfall.csv')\n",
    "updrs_future_sigfall_raw = pd.read_csv('./working_data/updrs_future_sigfall_raw.csv')\n",
    "\n",
    "datasets = [{'data':inc_updrs_sigfall, 'name':'inc_updrs_sigfall'},\n",
    "            {'data':inc_updrs_sigfall_raw, 'name':'inc_updrs_sigfall_raw'},\n",
    "            {'data':delta_updrs_sigfall , 'name':'delta_updrs_sigfall'},\n",
    "            {'data':delta_updrs_sigfall_raw , 'name':'delta_updrs_sigfall_raw'},\n",
    "            {'data':updrs_future_sigfall , 'name':'updrs_future_sigfall'},\n",
    "            {'data':updrs_future_sigfall_raw , 'name':'updrs_future_sigfall_raw'}\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7b3fc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models \n",
    "models = [\n",
    "    LinearDiscriminantAnalysis(solver=\"svd\"),\n",
    "    LinearDiscriminantAnalysis(solver=\"lsqr\"),\n",
    "    LinearDiscriminantAnalysis(solver=\"eigen\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b740dd27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For inc_updrs_sigfall, in model LinearDiscriminantAnalysis()\n",
      "Average NO SIGFALL accuracy is 0.9776946025409408\n",
      "Average SIGFALL accuracy is 0.12007940234976403\n",
      "---\n",
      "\n",
      "For inc_updrs_sigfall_raw, in model LinearDiscriminantAnalysis()\n",
      "Average NO SIGFALL accuracy is 0.9789396584431258\n",
      "Average SIGFALL accuracy is 0.11473078831966432\n",
      "---\n",
      "\n",
      "For delta_updrs_sigfall, in model LinearDiscriminantAnalysis()\n",
      "Average NO SIGFALL accuracy is 0.9951955087105154\n",
      "Average SIGFALL accuracy is 0.03445521863087324\n",
      "---\n",
      "\n",
      "For delta_updrs_sigfall_raw, in model LinearDiscriminantAnalysis()\n",
      "Average NO SIGFALL accuracy is 0.9952371579606898\n",
      "Average SIGFALL accuracy is 0.03439411465829157\n",
      "---\n",
      "\n",
      "For updrs_future_sigfall, in model LinearDiscriminantAnalysis()\n",
      "Average NO SIGFALL accuracy is 0.9839340988425781\n",
      "Average SIGFALL accuracy is 0.07352876867248571\n",
      "---\n",
      "\n",
      "For updrs_future_sigfall_raw, in model LinearDiscriminantAnalysis()\n",
      "Average NO SIGFALL accuracy is 0.9835045153478515\n",
      "Average SIGFALL accuracy is 0.07258726401658536\n",
      "---\n",
      "\n",
      "For inc_updrs_sigfall, in model LinearDiscriminantAnalysis(solver='lsqr')\n",
      "Average NO SIGFALL accuracy is 0.9790143686140138\n",
      "Average SIGFALL accuracy is 0.1194892568704099\n",
      "---\n",
      "\n",
      "For inc_updrs_sigfall_raw, in model LinearDiscriminantAnalysis(solver='lsqr')\n",
      "Average NO SIGFALL accuracy is 0.9788682091033105\n",
      "Average SIGFALL accuracy is 0.11459815000398302\n",
      "---\n",
      "\n",
      "For delta_updrs_sigfall, in model LinearDiscriminantAnalysis(solver='lsqr')\n",
      "Average NO SIGFALL accuracy is 0.995260252171881\n",
      "Average SIGFALL accuracy is 0.033219948400759\n",
      "---\n",
      "\n",
      "For delta_updrs_sigfall_raw, in model LinearDiscriminantAnalysis(solver='lsqr')\n",
      "Average NO SIGFALL accuracy is 0.9952856271152839\n",
      "Average SIGFALL accuracy is 0.03353593138111038\n",
      "---\n",
      "\n",
      "For updrs_future_sigfall, in model LinearDiscriminantAnalysis(solver='lsqr')\n",
      "Average NO SIGFALL accuracy is 0.983741482657691\n",
      "Average SIGFALL accuracy is 0.07315954072853319\n",
      "---\n",
      "\n",
      "For updrs_future_sigfall_raw, in model LinearDiscriminantAnalysis(solver='lsqr')\n",
      "Average NO SIGFALL accuracy is 0.9834823712372669\n",
      "Average SIGFALL accuracy is 0.07280844579840404\n",
      "---\n",
      "\n",
      "For inc_updrs_sigfall, in model LinearDiscriminantAnalysis(solver='eigen')\n",
      "Average NO SIGFALL accuracy is 0.9788066318963707\n",
      "Average SIGFALL accuracy is 0.11724759688700671\n",
      "---\n",
      "\n",
      "For inc_updrs_sigfall_raw, in model LinearDiscriminantAnalysis(solver='eigen')\n",
      "Average NO SIGFALL accuracy is 0.9787289287712091\n",
      "Average SIGFALL accuracy is 0.11363629994287136\n",
      "---\n",
      "\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "The leading minor of order 14 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_67/2029887192.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtests\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dataset'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'specificity'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'specificity'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sensitivity'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sensitivity'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_67/2645761848.py\u001b[0m in \u001b[0;36mgenerate_scores\u001b[0;34m(dataset, model)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mspecificity_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspecificity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0msensitivity_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msensitivity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_67/2645761848.py\u001b[0m in \u001b[0;36mbuild_confusion_matrix\u001b[0;34m(dataset, model)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbuild_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mtn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'true_negative'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'false_negative'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'false_positive'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'true_positive'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/discriminant_analysis.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    597\u001b[0m             )\n\u001b[1;32m    598\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"eigen\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m             self._solve_eigen(\n\u001b[0m\u001b[1;32m    600\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/discriminant_analysis.py\u001b[0m in \u001b[0;36m_solve_eigen\u001b[0;34m(self, X, y, shrinkage, covariance_estimator)\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0mSb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSt\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mSw\u001b[0m  \u001b[0;31m# between scatter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meigh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m         self.explained_variance_ratio_ = np.sort(evals / np.sum(evals))[::-1][\n\u001b[1;32m    442\u001b[0m             \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_components\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/scipy/linalg/decomp.py\u001b[0m in \u001b[0;36meigh\u001b[0;34m(a, b, lower, eigvals_only, overwrite_a, overwrite_b, turbo, eigvals, type, check_finite, subset_by_index, subset_by_value, driver)\u001b[0m\n\u001b[1;32m    576\u001b[0m                               ''.format(-info, drv.typecode + pfx + driver))\n\u001b[1;32m    577\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m             raise LinAlgError('The leading minor of order {} of B is not '\n\u001b[0m\u001b[1;32m    579\u001b[0m                               \u001b[0;34m'positive definite. The factorization of B '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m                               \u001b[0;34m'could not be completed and no eigenvalues '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLinAlgError\u001b[0m: The leading minor of order 14 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed."
     ]
    }
   ],
   "source": [
    "# Run tests\n",
    "\n",
    "tests = []\n",
    "for m in models:\n",
    "    for d in datasets:\n",
    "        tests.append({\n",
    "            'data_name': d['name'],\n",
    "            'dataset': d['data'],\n",
    "            'model': m\n",
    "        })\n",
    "\n",
    "for t in tests:\n",
    "    s = generate_scores(dataset=t['dataset'], model=t['model'])\n",
    "    t['specificity'] = s['specificity']\n",
    "    t['sensitivity'] = s['sensitivity']\n",
    "    summarise_test(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b7eb939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See QDA notebook for implementation of 'Balanced Datasets' - not sure its a valid thing to do ATM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
