{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d2efe76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "def build_confusion_matrix(dataset, model):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(dataset.iloc[:, :-1], dataset.iloc[:, -1], test_size=0.25)\n",
    "        predictions = model.fit(X_train, y_train).predict(X_test)\n",
    "        tn, fn, fp, tp = confusion_matrix(predictions, y_test.values).ravel()\n",
    "        return {'true_negative': tn, 'false_negative': fn, 'false_positive': fp, 'true_positive': tp}\n",
    "\n",
    "def sensitivity(cm):\n",
    "    return cm['true_positive'] / (cm['true_positive'] + cm['false_negative'])\n",
    "\n",
    "def specificity(cm):\n",
    "    return cm['true_negative'] / ( cm['true_negative'] + cm['false_positive'] )\n",
    "\n",
    "def false_positive_rate(cm):\n",
    "    return (1.0 - (specificity(cm)) )\n",
    "\n",
    "def generate_scores(dataset, model):\n",
    "    specificity_scores = []\n",
    "    sensitivity_scores = []\n",
    "\n",
    "    for n in range(1000):\n",
    "        cm = build_confusion_matrix(dataset, model)\n",
    "        specificity_scores.append(specificity(cm))\n",
    "        sensitivity_scores.append(sensitivity(cm))\n",
    "    \n",
    "    spec_avg = pd.Series(specificity_scores).mean()\n",
    "    sens_avg = pd.Series(sensitivity_scores).mean()\n",
    "    \n",
    "    return {'specificity': spec_avg, 'sensitivity': sens_avg }\n",
    "\n",
    "def summarise_test(test):\n",
    "    x ='For {}, in model {}\\nAverage NO SIGFALL accuracy is {}\\nAverage SIGFALL accuracy is {}\\n---\\n'\n",
    "    print(x.format(test['data_name'],test['model'],test['specificity'],test['sensitivity']))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "408431ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data sets\n",
    "inc_updrs_sigfall = pd.read_csv('./working_data/normalised_increase_updrs_sigfall.csv')\n",
    "inc_updrs_sigfall_raw = pd.read_csv('./working_data/normalised_increase_updrs_sigfall_raw.csv')\n",
    "\n",
    "datasets = [{'data':inc_updrs_sigfall, 'name':'inc_updrs_sigfall'}, \n",
    "            {'data':inc_updrs_sigfall_raw, 'name':'inc_updrs_sigfall_raw'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fafff327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0 --- 1\n",
      "0.8563502958450656\n",
      "0.4019338500599539\n",
      "\n",
      "\n",
      "--- 0 --- 101\n",
      "0.8580780199747803\n",
      "0.401576093524014\n",
      "\n",
      "\n",
      "--- 0 --- 201\n",
      "0.8572664316406499\n",
      "0.40052575404731433\n",
      "\n",
      "\n",
      "--- 0 --- 301\n",
      "0.857884307650238\n",
      "0.40326144587668017\n",
      "\n",
      "\n",
      "--- 0 --- 401\n",
      "0.8575113049216329\n",
      "0.4026009179263204\n",
      "\n",
      "\n",
      "--- 0 --- 501\n",
      "0.8582181776830138\n",
      "0.40371912299222373\n",
      "\n",
      "\n",
      "--- 0 --- 601\n",
      "0.8564617142800797\n",
      "0.4014214797876678\n",
      "\n",
      "\n",
      "--- 0 --- 701\n",
      "0.8576404473274515\n",
      "0.40375439959641846\n",
      "\n",
      "\n",
      "--- 0 --- 801\n",
      "0.8564426124167857\n",
      "0.40224346436078523\n",
      "\n",
      "\n",
      "--- 0 --- 901\n",
      "0.8576523689852742\n",
      "0.4068723959017821\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes Specific:\n",
    "# Does sample weighting affect the model accuracy?  -> Apparently not...\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(inc_updrs_sigfall.iloc[:, :-1], inc_updrs_sigfall.iloc[:, -1], test_size=0.25)\n",
    "\n",
    "for n in range(1,1000,100):\n",
    "    m = GaussianNB()\n",
    "    m.fit(X_train, y_train, sample_weight=compute_sample_weight(class_weight={0.0:1, 1.0:n}, y=y_train))\n",
    "    print(f'--- {0} ---',n)\n",
    "    s = generate_scores(dataset=inc_updrs_sigfall, model=m)\n",
    "    print(s['specificity'])\n",
    "    print(s['sensitivity'])\n",
    "    print('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "391cc50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For inc_updrs_sigfall, in model GaussianNB(priors=[0.01, 0.99])\n",
      "Average NO SIGFALL accuracy is 0.6300051867546457\n",
      "Average SIGFALL accuracy is 0.7218809201318153\n",
      "---\n",
      "\n",
      "For inc_updrs_sigfall_raw, in model GaussianNB(priors=[0.01, 0.99])\n",
      "Average NO SIGFALL accuracy is 0.5825687421865834\n",
      "Average SIGFALL accuracy is 0.7673746007543895\n",
      "---\n",
      "\n",
      "For inc_updrs_sigfall, in model GaussianNB(priors=[0.03, 0.97])\n",
      "Average NO SIGFALL accuracy is 0.6949915894282488\n",
      "Average SIGFALL accuracy is 0.6722877222018036\n",
      "---\n",
      "\n",
      "For inc_updrs_sigfall_raw, in model GaussianNB(priors=[0.03, 0.97])\n",
      "Average NO SIGFALL accuracy is 0.6654005199516219\n",
      "Average SIGFALL accuracy is 0.706691030079475\n",
      "---\n",
      "\n",
      "For inc_updrs_sigfall, in model GaussianNB(priors=[0.05, 0.95])\n",
      "Average NO SIGFALL accuracy is 0.719784438426294\n",
      "Average SIGFALL accuracy is 0.631788893246653\n",
      "---\n",
      "\n",
      "For inc_updrs_sigfall_raw, in model GaussianNB(priors=[0.05, 0.95])\n",
      "Average NO SIGFALL accuracy is 0.6944348405260808\n",
      "Average SIGFALL accuracy is 0.6706149247306364\n",
      "---\n",
      "\n",
      "For inc_updrs_sigfall, in model GaussianNB(priors=[0.07, 0.93])\n",
      "Average NO SIGFALL accuracy is 0.7349072054760472\n",
      "Average SIGFALL accuracy is 0.6037269937923527\n",
      "---\n",
      "\n",
      "For inc_updrs_sigfall_raw, in model GaussianNB(priors=[0.07, 0.93])\n",
      "Average NO SIGFALL accuracy is 0.712385619451334\n",
      "Average SIGFALL accuracy is 0.6469863608615303\n",
      "---\n",
      "\n",
      "For inc_updrs_sigfall, in model GaussianNB(priors=[0.09, 0.91])\n",
      "Average NO SIGFALL accuracy is 0.7465943675196977\n",
      "Average SIGFALL accuracy is 0.5894850986873609\n",
      "---\n",
      "\n",
      "For inc_updrs_sigfall_raw, in model GaussianNB(priors=[0.09, 0.91])\n",
      "Average NO SIGFALL accuracy is 0.7253093854429772\n",
      "Average SIGFALL accuracy is 0.6182989127817937\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run tests to score each model & dataset combination\n",
    "\n",
    "models = [\n",
    "    GaussianNB(priors=[0.01,0.99]),\n",
    "    GaussianNB(priors=[0.03,0.97]),\n",
    "    GaussianNB(priors=[0.05,0.95]),\n",
    "    GaussianNB(priors=[0.07,0.93]),\n",
    "    GaussianNB(priors=[0.09,0.91])\n",
    "    GaussianNB(priors=[0.2,0.8]),\n",
    "    GaussianNB(priors=[0.3,0.7]),\n",
    "    GaussianNB(priors=[0.4,0.6]),\n",
    "    GaussianNB(priors=[0.5,0.5]),\n",
    "]\n",
    "\n",
    "tests = []\n",
    "for m in models:\n",
    "    for d in datasets:\n",
    "        tests.append({\n",
    "            'data_name': d['name'],\n",
    "            'dataset': d['data'],\n",
    "            'model': m\n",
    "        })\n",
    "\n",
    "for t in tests:\n",
    "    s = generate_scores(dataset=t['dataset'], model=t['model'])\n",
    "    t['specificity'] = s['specificity']\n",
    "    t['sensitivity'] = s['sensitivity']\n",
    "    summarise_test(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea28fafd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
